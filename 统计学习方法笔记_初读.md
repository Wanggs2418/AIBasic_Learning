# 统计学习方法

## 1. 统计及监督学习概论

### 1.1 统计学习

统计学习关于数据的基本假设是**同类数据具有一定的统计规律性**。比如，可用随机变量描述数据中的特征，概率分布描述数据的统计规律。

统计学习的方法是基于数据构建概率统计模型实现对数据的预测和分析。统计学习由监督学习 (supervised learning)、无监督学习 (unsupervised learning) 和强化学习 (reinforcement learning) 等组成。

统计学习的三要素：模型 (model)、策略 (strategy)、算法 (algorithm)。

- 从有限的训练数据集出发，确定所有模型的假设空间 (hypothesis space)，即**学习模型的集合**
- 确定模型的选择准则，即**学习的策略**
- 从中选择一个最优的模型，即**学习的算法**
- 利用学习的最优模型对新数据进行预测或分析

### 1.2 分类

**1.基本分类**

**监督学习 (supervised learning)**

监督学习的本质是学习输入到输出映射的统计规律。

**无监督学习 (unsupervised learning)**

本质是学习数据中的统计规律或潜在结构

**强化学习 (reinforcement learning)**

智能系统在与环境的连续互动中学习最优行为测略的机器学习问题，本质是**学习最优的序贯决策**。

智能系统的目标是长期积累奖励的最大化。强化学习过程中，系统不断试错 (trial error)，以达到学习最优最优策略的目的。

强化学习方法中有基于策略的 (policy-based)、基于价值的 (value-based)，这两者都属于无模型(model-free)的方法。

**半监督学习和主动学习**

更靠近监督学习的范畴。

利用标注数据和未标注数据学习预测模型的机器学习问题。通常有少量标注数据、大量未标注数据。半监督学习旨在利用未标注数据中的信息，辅助标注数据，进行监督学习，以较低的成本达到较好的学习效果。

主动学习是指机器不断主动给出实例让人进行标注，而后利用标注数据学习预测模型的机器学习问题。**其目标是找出对学习最有帮助的实例让人标注，即以较小的标注代价达到较好的学习效果。**

**2.按模型分类**

**概率模型和非概率模型**

监督学习中，概率模型是**生成模型**，非概率模型是**判别模型**，概率模型一定可以表示为联合概率分布形式。

监督学习中 $x$ 输入，$y$ 输出：

- 概率模型取条件概率分布形式 $P(y|x)$
- 非概率模型取函数形式 $y=f(x)$

无监督学习中 $x$ 输入，$z$ 输出 (如 RL)：

- 概率模型取条件概率分布形式 $P(z|x)$ 或 $P(x|z)$
- 非概率模型取函数形式 $z=g(x)$

条件概率最大化后得到函数，函数归一化后得到条件概率分布。概率模型和非概率模型的区别在于**模型的内在结构**，概率模型的典型代表是概率图模型 (probabilistic graphical model)。

**线性模型和非线性模型**

尤其对于非概率模型来说

**参数化模型和非参数化模型**

参数化模型可以由有限参数完全刻画；非参数化模型的参数则随着数据量的增加而不断加大

**3.按算法分**

在线学习 (online learning) 与批量学习 (batch learning)。

**在线学习**：每次接收一个样本，进行预测，之后进行学习

**批量学习**：一次接收所有数据，学习模型，之后进行预测

利用梯度随机下降的感知机学习算法就是在线学习，在线学习通常比批量学习更难，因为每次模型更新中，可利用的数据有限。

**4.按技巧分类**

**贝叶斯学习(Bayesian learning)**

计算在给定数据条件下模型的条件概率，即后验概率。

**核方法 (kernel method)**

使用核函数，映射到特征空间的内积，将线性模型扩展到非线性模型。

### 1.3 统计学习方法三要素

模型 + 策略 + 算法

**模型**

要学习的条件概率分布或决策函数，它们所有可能的集合构成模型的假设空间 (hypothesis space)

**策略**

**对监督学习来说，转化为经验风险或结构风险函数最优化的问题，此时的经验函数或结构风险函数就是最优化的目标函数。**

选出最优的模型:

- 模型**关于真实联合分布** $P(X,Y)$ 平均意义下的损失，称为风险函数 (risk function) / 期望损失 (expected loss)

- **关于训练数据集**的平均损失称为风险经验 (empirical risk) / 经验损失 (empirical loss)

样本足够大时，经验风险趋近于期望风险。实际数据集较小，用经验风险估计期望风险的误差较大，需要进行修正。即经验风险最小化 (empirical risk minimization，ERM) 和结构风险最小化 (structural risk minimization，SRM)。

- **ERM**：样本足够大时，ERM 效果很好；如极大似然估计 (MLE)；样本容量很小时，经验风险未必很好，容易产生过拟合现象。
- **SRM**：防止过拟合，等价于正则化；其在 ERM 的基础上增加了正则化项和罚项 (penalty term)；最终要求经验风险与模型复杂度同时小

例如：贝叶斯估计中的最大后验概率估计 (maximum posterior probability estimation，MAP) 就是结构风险最小化的例子。

- 模型为条件概率分布，损伤函数是对数函数，经验风险最小化等价于极大似然估计
- 模型为条件概率分布，损伤函数是对数函数，模型的复杂度用模型的先验概率表示，结构风险最小化等价于最大后验概率估计。

**算法**

根据学习策略从假设空间中选择最优的模型，算法则是学习模型的具体计算方法。

### 1.4 模型的评估和选择

要求学习到的模型对已知数据和未知数据都能有很好的预测能力，测试误差表示学习方法对未知数据的预测能力，即为泛化能力 (generalization ability)。

在训练时要防止过拟合，选择复杂度适当的模型，达到使测试误差最小的学习目的。

### 1.5 正则化与交叉验证

**正则化**

结构风险最小化的实现，正则化项是模型的复杂度的单调递增函数，可以是模型参数向量的范数。

选择经验风险和模型复杂度同时较小的模型；

**交叉验证**

cross validation，数据足够时，直接划分：训练集用于训练模型；验证集用于模型的选择；测试集用于对最终方法的评估。

数据不充足，使用交叉验证：

- 简单的交叉验证，随机划分为两部分
- S 折交叉验证 (S-fold cross validation)，随机将数据划分为 S 个互不相交等规模子集，用 S-1 个进行训练，余下的用于测试；可进行 S 次，最后选出 S 次平均测试误差最小的模型。

- 留一交叉验证 (leave-one-out cross validation)，即划分的子集个数 S 和数据个数 N 一样，数据很缺乏的情况

### 1.6 泛化能力

泛化误差 (generalization error)：方法学习到的模型对未知数据的预测误差。实际采取的方法往往依赖于测试集进行评判，测试集的好坏直接关系到模型的评估结果的可靠性。

泛化能力分析往往通过泛化误差上界 (generalization error bound) 进行：

- 其是样本容量的函数，容量增加，泛化上界趋于 0
- 也是假设空间容量 (capacity) 的函数，假设空间容量越大，模型越难学，泛化误差就越大

<img src="img/01.jpg" style="zoom:80%;" />

er





































